{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8163265306122449,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0163265306122449,
      "grad_norm": 0.6070590615272522,
      "learning_rate": 0.00019902120717781404,
      "loss": 2.5487,
      "step": 10
    },
    {
      "epoch": 0.0326530612244898,
      "grad_norm": 1.049483060836792,
      "learning_rate": 0.00019793365959760743,
      "loss": 2.064,
      "step": 20
    },
    {
      "epoch": 0.04897959183673469,
      "grad_norm": 0.3615463972091675,
      "learning_rate": 0.00019684611201740079,
      "loss": 1.9007,
      "step": 30
    },
    {
      "epoch": 0.0653061224489796,
      "grad_norm": 0.2845410108566284,
      "learning_rate": 0.00019575856443719415,
      "loss": 1.8886,
      "step": 40
    },
    {
      "epoch": 0.08163265306122448,
      "grad_norm": 0.3410886526107788,
      "learning_rate": 0.0001946710168569875,
      "loss": 1.8426,
      "step": 50
    },
    {
      "epoch": 0.09795918367346938,
      "grad_norm": 0.30703961849212646,
      "learning_rate": 0.00019358346927678087,
      "loss": 1.8371,
      "step": 60
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.31881651282310486,
      "learning_rate": 0.00019249592169657425,
      "loss": 1.9293,
      "step": 70
    },
    {
      "epoch": 0.1306122448979592,
      "grad_norm": 0.2803342938423157,
      "learning_rate": 0.0001914083741163676,
      "loss": 1.818,
      "step": 80
    },
    {
      "epoch": 0.1469387755102041,
      "grad_norm": 0.37725797295570374,
      "learning_rate": 0.00019032082653616097,
      "loss": 1.8202,
      "step": 90
    },
    {
      "epoch": 0.16326530612244897,
      "grad_norm": 0.35854172706604004,
      "learning_rate": 0.00018923327895595433,
      "loss": 1.8213,
      "step": 100
    },
    {
      "epoch": 0.17959183673469387,
      "grad_norm": 0.3202967047691345,
      "learning_rate": 0.0001881457313757477,
      "loss": 1.8243,
      "step": 110
    },
    {
      "epoch": 0.19591836734693877,
      "grad_norm": 0.3223319351673126,
      "learning_rate": 0.00018705818379554105,
      "loss": 1.8553,
      "step": 120
    },
    {
      "epoch": 0.21224489795918366,
      "grad_norm": 0.3044050335884094,
      "learning_rate": 0.00018597063621533444,
      "loss": 1.804,
      "step": 130
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.2949411869049072,
      "learning_rate": 0.0001848830886351278,
      "loss": 1.8266,
      "step": 140
    },
    {
      "epoch": 0.24489795918367346,
      "grad_norm": 0.31954482197761536,
      "learning_rate": 0.00018379554105492116,
      "loss": 1.7876,
      "step": 150
    },
    {
      "epoch": 0.2612244897959184,
      "grad_norm": 0.32863157987594604,
      "learning_rate": 0.00018270799347471452,
      "loss": 1.8,
      "step": 160
    },
    {
      "epoch": 0.27755102040816326,
      "grad_norm": 0.3236066997051239,
      "learning_rate": 0.00018162044589450788,
      "loss": 1.8107,
      "step": 170
    },
    {
      "epoch": 0.2938775510204082,
      "grad_norm": 0.31270483136177063,
      "learning_rate": 0.00018053289831430127,
      "loss": 1.8301,
      "step": 180
    },
    {
      "epoch": 0.31020408163265306,
      "grad_norm": 0.2875197231769562,
      "learning_rate": 0.00017944535073409463,
      "loss": 1.7883,
      "step": 190
    },
    {
      "epoch": 0.32653061224489793,
      "grad_norm": 0.3045722544193268,
      "learning_rate": 0.000178357803153888,
      "loss": 1.726,
      "step": 200
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.42726588249206543,
      "learning_rate": 0.00017727025557368135,
      "loss": 1.7654,
      "step": 210
    },
    {
      "epoch": 0.35918367346938773,
      "grad_norm": 0.3126099407672882,
      "learning_rate": 0.0001761827079934747,
      "loss": 1.7919,
      "step": 220
    },
    {
      "epoch": 0.37551020408163266,
      "grad_norm": 0.3070201873779297,
      "learning_rate": 0.00017509516041326807,
      "loss": 1.8171,
      "step": 230
    },
    {
      "epoch": 0.39183673469387753,
      "grad_norm": 0.31151145696640015,
      "learning_rate": 0.00017400761283306145,
      "loss": 1.7921,
      "step": 240
    },
    {
      "epoch": 0.40816326530612246,
      "grad_norm": 0.3321877419948578,
      "learning_rate": 0.00017292006525285481,
      "loss": 1.7703,
      "step": 250
    },
    {
      "epoch": 0.42448979591836733,
      "grad_norm": 0.37979647517204285,
      "learning_rate": 0.00017183251767264817,
      "loss": 1.8107,
      "step": 260
    },
    {
      "epoch": 0.44081632653061226,
      "grad_norm": 0.4087633192539215,
      "learning_rate": 0.00017074497009244153,
      "loss": 1.7817,
      "step": 270
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.3711621165275574,
      "learning_rate": 0.00016965742251223492,
      "loss": 1.7706,
      "step": 280
    },
    {
      "epoch": 0.47346938775510206,
      "grad_norm": 0.34205716848373413,
      "learning_rate": 0.00016856987493202828,
      "loss": 1.7466,
      "step": 290
    },
    {
      "epoch": 0.4897959183673469,
      "grad_norm": 0.3816305994987488,
      "learning_rate": 0.00016748232735182167,
      "loss": 1.7623,
      "step": 300
    },
    {
      "epoch": 0.5061224489795918,
      "grad_norm": 0.2984622120857239,
      "learning_rate": 0.00016639477977161503,
      "loss": 1.7816,
      "step": 310
    },
    {
      "epoch": 0.5224489795918368,
      "grad_norm": 0.33755743503570557,
      "learning_rate": 0.0001653072321914084,
      "loss": 1.73,
      "step": 320
    },
    {
      "epoch": 0.5387755102040817,
      "grad_norm": 0.28599584102630615,
      "learning_rate": 0.00016421968461120175,
      "loss": 1.7403,
      "step": 330
    },
    {
      "epoch": 0.5551020408163265,
      "grad_norm": 0.3225797712802887,
      "learning_rate": 0.00016313213703099514,
      "loss": 1.8141,
      "step": 340
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.34483781456947327,
      "learning_rate": 0.0001620445894507885,
      "loss": 1.7454,
      "step": 350
    },
    {
      "epoch": 0.5877551020408164,
      "grad_norm": 0.3487129211425781,
      "learning_rate": 0.00016095704187058186,
      "loss": 1.7941,
      "step": 360
    },
    {
      "epoch": 0.6040816326530613,
      "grad_norm": 0.33115166425704956,
      "learning_rate": 0.00015986949429037522,
      "loss": 1.8038,
      "step": 370
    },
    {
      "epoch": 0.6204081632653061,
      "grad_norm": 0.3212842643260956,
      "learning_rate": 0.00015878194671016858,
      "loss": 1.7753,
      "step": 380
    },
    {
      "epoch": 0.636734693877551,
      "grad_norm": 0.33445823192596436,
      "learning_rate": 0.00015769439912996194,
      "loss": 1.7847,
      "step": 390
    },
    {
      "epoch": 0.6530612244897959,
      "grad_norm": 0.3554426431655884,
      "learning_rate": 0.00015660685154975532,
      "loss": 1.747,
      "step": 400
    },
    {
      "epoch": 0.6693877551020408,
      "grad_norm": 0.391044557094574,
      "learning_rate": 0.00015551930396954868,
      "loss": 1.7959,
      "step": 410
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 0.3506777882575989,
      "learning_rate": 0.00015443175638934204,
      "loss": 1.7358,
      "step": 420
    },
    {
      "epoch": 0.7020408163265306,
      "grad_norm": 0.3637069761753082,
      "learning_rate": 0.0001533442088091354,
      "loss": 1.7738,
      "step": 430
    },
    {
      "epoch": 0.7183673469387755,
      "grad_norm": 0.32512950897216797,
      "learning_rate": 0.00015225666122892876,
      "loss": 1.7895,
      "step": 440
    },
    {
      "epoch": 0.7346938775510204,
      "grad_norm": 0.30562251806259155,
      "learning_rate": 0.00015116911364872215,
      "loss": 1.7917,
      "step": 450
    },
    {
      "epoch": 0.7510204081632653,
      "grad_norm": 0.31879860162734985,
      "learning_rate": 0.0001500815660685155,
      "loss": 1.7348,
      "step": 460
    },
    {
      "epoch": 0.7673469387755102,
      "grad_norm": 0.3439510464668274,
      "learning_rate": 0.00014899401848830887,
      "loss": 1.7827,
      "step": 470
    },
    {
      "epoch": 0.7836734693877551,
      "grad_norm": 0.37851470708847046,
      "learning_rate": 0.00014790647090810223,
      "loss": 1.7644,
      "step": 480
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.35986047983169556,
      "learning_rate": 0.0001468189233278956,
      "loss": 1.7609,
      "step": 490
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 0.3248812258243561,
      "learning_rate": 0.00014573137574768895,
      "loss": 1.7945,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 1839,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.59617862598656e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
