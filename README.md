# ğŸŒ English-to-Chinese Machine Translation with DeepSeek-LLM + LoRA

This project fine-tunes the open-source DeepSeek-LLM on the [WMT19 Zh-En dataset](https://www.statmt.org/wmt19/translation-task.html) using parameter-efficient LoRA training. The pipeline includes data preprocessing, tokenization, training, inference, evaluation, deployment, and a web UI.

---

## ğŸ“Œ Project Structure

```bash
Fine-tuning/
â”œâ”€â”€ data/                 # Raw + tokenized data
â”œâ”€â”€ preprocess/           # Scripts for data preprocessing
â”œâ”€â”€ train/                # Training with LoRA
â”œâ”€â”€ inference/            # Inference scripts + API + Web UI
â”œâ”€â”€ deployment/           # Final merged model for deployment
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md / README_zh.md
```

---

## ğŸ§ª Features

- âœ… Hugging Face Transformers compatible
- âœ… Efficient fine-tuning with LoRA
- âœ… Support for GPU/CPU inference
- âœ… BLEU evaluation and batched result export
- âœ… Flask API service and lightweight Web UI

---

## ğŸ§± Tech Stack & Dependencies

| Library        | Description                      |
|----------------|----------------------------------|
| `transformers` | Hugging Face model framework     |
| `peft`         | Parameter-efficient fine-tuning  |
| `datasets`     | Data loading and formatting      |
| `bitsandbytes` | 4-bit quantization support       |
| `evaluate`     | BLEU scoring                     |
| `flask`        | RESTful API + Web interface      |
| `torch`        | Deep learning backend            |

Install via:

```bash
pip install -r requirements.txt
```

---

## ğŸ“‚ Dataset Description

- Source: WMT19 En-Zh Translation Task
- Format: JSONL with `prompt` and `response`

Example:

```json
{"prompt": "Translate to Chinese: How are you?", "response": "ä½ å¥½å—ï¼Ÿ"}
```

---

## ğŸš€ Quick Start

```bash
# Preprocess
python preprocess/preprocess_wmt19.py
python preprocess/tokenize_and_prepare.py

# Train
python train/train_lora.py

# Inference (single sample)
python inference/infer_one.py

# Batch generation
python inference/generate_predictions.py

# BLEU evaluation
python inference/evaluate_bleu.py

# Launch API
python inference/app_api.py

# Launch Web UI
python inference/app_webui.py
```

---

## ğŸ§Š Model Merge & Deployment

Merge adapter and save model for deployment:

```bash
python save_merged_model.py
```

Saves to: `deployment/merged_model` and `.zip`

---

## ğŸ“Š Example Output

Source:

```
The challenge will be to reach an agreement that guarantees the wellbeing of future EU-UK relations.
```

Translation:

```
æŒ‘æˆ˜åœ¨äºè¾¾æˆä¸€ä»½ä¿éšœæœªæ¥æ¬§ç›Ÿ-è‹±å›½å…³ç³»ç¦ç¥‰çš„åè®®ã€‚
```

---

## ğŸ“¬ Acknowledgments

Built with ChatGPT, DeepSeek-LLM, Hugging Face Transformers, and WMT19. Thanks to the open-source community!
