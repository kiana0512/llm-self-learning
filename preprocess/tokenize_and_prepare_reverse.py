from datasets import load_dataset, Dataset
from transformers import AutoTokenizer
from pathlib import Path
import os

# æ¨¡å‹å’Œè·¯å¾„
model_name = "deepseek-ai/deepseek-llm-7b-base"
data_path = "../data/wmt19_en_zh_reversed.jsonl"
save_path = "../data/tokenized_wmt19_en_zh_reversed"

# åŠ è½½æ•°æ®é›†
print("ğŸ“‚ åŠ è½½æ•°æ®æ–‡ä»¶:", data_path)
raw_dataset = Dataset.from_json(data_path)

# åŠ è½½åˆ†è¯å™¨
print("ğŸ”„ åŠ è½½ Tokenizerï¼š", model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

# åˆ†è¯å‡½æ•°
def prepare_dataset(example):
    model_input = tokenizer(example["prompt"], truncation=True, padding="max_length", max_length=512)
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(example["response"], truncation=True, padding="max_length", max_length=512)
    model_input["labels"] = labels["input_ids"]
    return model_input

# æ‰§è¡Œæ˜ å°„
print("ğŸ§¹ æ‰§è¡Œåˆ†è¯...")
tokenized_dataset = raw_dataset.map(prepare_dataset)

# ä¿å­˜åˆ°ç£ç›˜
print(f"ğŸ’¾ ä¿å­˜è‡³ {save_path}")
tokenized_dataset.save_to_disk(save_path)
print(f"âœ… æ•°æ®é›†æ„å»ºå®Œæˆã€‚æ ·æœ¬æ€»æ•°: {len(tokenized_dataset)}")
