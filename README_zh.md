# ğŸ“˜ åŸºäº DeepSeek-LLM çš„ä¸­è‹±ç¿»è¯‘æ¨¡å‹å¾®è°ƒé¡¹ç›®

## ğŸ” é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®åŸºäº Hugging Face Transformers æ¡†æ¶ï¼Œé‡‡ç”¨ DeepSeek-LLM 7B é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œå¯¹ WMT19 ä¸­æ–‡-è‹±æ–‡ç¿»è¯‘æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚é€šè¿‡å¼•å…¥ PEFT ä¸­çš„ LoRA æŠ€æœ¯å’Œ bitsandbytes çš„ 4bit å‚æ•°é‡åŒ–æ–¹æ³•ï¼Œå®ç°é«˜æ•ˆä¸”ä½èµ„æºæ¶ˆè€—çš„å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒæµç¨‹ï¼Œé€‚ç”¨äºç§‘ç ”ã€æ•™å­¦æˆ–äº§å“åŸå‹å¼€å‘ã€‚

## ğŸ§  é¡¹ç›®ç›®æ ‡

- åŠ è½½å¹¶é¢„å¤„ç† WMT19 zh-en æ•°æ®é›†
- ä½¿ç”¨ DeepSeek-LLM ä½œä¸ºåŸºç¡€æ¨¡å‹
- åº”ç”¨ LoRAï¼ˆLow-Rank Adaptationï¼‰è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ
- å¼•å…¥ 4bit é‡åŒ–å‡å°‘æ˜¾å­˜å ç”¨
- æ”¯æŒåç»­æ¨ç†éƒ¨ç½²ä¸è¯„ä¼°ï¼ˆBLEU/chrFï¼‰

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```bash
Fine-tuning/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ tokenized_wmt19_zh_en/
â”œâ”€â”€ preprocess/
â”‚   â”œâ”€â”€ load_wmt.py
â”‚   â””â”€â”€ tokenize_and_prepare.py
â”œâ”€â”€ train/
â”‚   â””â”€â”€ train_lora.py
â””â”€â”€ README.md
```

## ğŸ“¦ æŠ€æœ¯æ ˆä¸ä¾èµ–

| åº“               | è¯´æ˜                         |
|------------------|------------------------------|
| `transformers` â‰¥ 4.40 | è¯­è¨€æ¨¡å‹/å¾®è°ƒä¸»æ¡†æ¶          |
| `peft` â‰¥ 0.10         | å‚æ•°é«˜æ•ˆå¾®è°ƒæ¨¡å—ï¼ˆLoRAï¼‰     |
| `datasets`           | æ•°æ®é›†å¤„ç†ä¸åºåˆ—åŒ–           |
| `bitsandbytes`       | æƒé‡é‡åŒ–æ”¯æŒï¼ˆ4bitï¼‰         |
| `torch`              | æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶             |
| `accelerate`         | åŠ é€Ÿå™¨ï¼ˆè‡ªåŠ¨è®¾å¤‡æ˜ å°„ï¼‰       |

## ğŸ“š æ•°æ®é›†è¯´æ˜

- æ•°æ®æ¥æºï¼š[WMT19 ä¸­è‹±ç¿»è¯‘ä»»åŠ¡](https://www.statmt.org/wmt19/translation-task.html)
- æ ¼å¼ï¼šåŸå§‹ä¸­è‹±æ–‡æœ¬å¯¹
- åˆ†è¯æ–¹æ³•ï¼šä½¿ç”¨ DeepSeek tokenizerï¼Œä¿å­˜ä¸º HF Dataset æ ¼å¼

## ğŸš€ å¾®è°ƒæµç¨‹

```bash
conda activate deepseek_lora
python train/train_lora.py
```

è®­ç»ƒé…ç½®å‚æ•°ï¼š

- Epochs: 3
- Batch Size: 2
- LoRA: r=8, alpha=16, dropout=0.05
- æ¨¡å‹åŠ è½½ï¼š4bit é‡åŒ– + bf16 ç²¾åº¦

## ğŸ“ˆ æ¨¡å‹ä¿å­˜ä¸æ¨ç†

æ¨¡å‹ä¿å­˜è·¯å¾„ï¼š

```bash
./lora_output/
```

åŠ è½½æ–¹å¼ï¼š

```python
from transformers import AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained("./lora_output")
```

## ğŸ”§ ç¯å¢ƒé…ç½®æ¨è

```bash
conda create -n deepseek_lora python=3.10 -y
conda activate deepseek_lora

pip install torch==2.2.2+cu121 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers==4.40.1 peft==0.10.0 datasets accelerate bitsandbytes safetensors tokenizers tqdm
```

## ğŸ“Œ ä½œè€…ä¿¡æ¯

- GitHub: [kiana0512](https://github.com/kiana0512)
- é¡¹ç›®è·¯å¾„ï¼š`F:\python_project\Fine-tuning`
